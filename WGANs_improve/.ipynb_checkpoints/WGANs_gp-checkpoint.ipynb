{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def variable_init(size):\n",
    "    in_dim = size[0]\n",
    "#     variable_stddev = 1./tf.sqrt(in_dim/2.)\n",
    "    variable_stddev = tf.sqrt(2./in_dim)\n",
    "    return tf.random_normal(shape=size,stddev=variable_stddev)\n",
    "#     return tf.random_normal(shape=size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mb_size = 32\n",
    "Z_dim = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None,784])\n",
    "\n",
    "D_W1 = tf.Variable(variable_init([784,128]))\n",
    "D_b1 = tf.Variable(tf.zeros(shape=[128]))\n",
    "\n",
    "D_W2 = tf.Variable(variable_init([128, 1]))\n",
    "D_b2 = tf.Variable(tf.zeros(shape=[1]))\n",
    "\n",
    "theta_D = [D_W1, D_W2, D_b1, D_b2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Z = tf.placeholder(tf.float32, shape=[None, Z_dim])\n",
    "\n",
    "G_W1 = tf.Variable(variable_init([Z_dim,128]))\n",
    "G_b1 = tf.Variable(tf.zeros(shape=[128]))\n",
    "\n",
    "G_W2 = tf.Variable(variable_init([128,784]))\n",
    "G_b2 = tf.Variable(tf.zeros(shape=[784]))\n",
    "\n",
    "theta_G = [G_W1, G_W2, G_b1, G_b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_Z(m,n):\n",
    "    return np.random.uniform(-1., 1., size=[m,n])\n",
    "def sample_epsilon:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator(z):\n",
    "    G_h1 = tf.nn.relu(tf.matmul(z, G_W1) + G_b1)\n",
    "    G_prob = tf.nn.sigmoid(tf.matmul(G_h1, G_W2) + G_b2)\n",
    "    return G_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discriminator(x):\n",
    "    D_h1 = tf.nn.relu(tf.matmul(x, D_W1) + D_b1)\n",
    "    D_logit = tf.matmul(D_h1, D_W2) + D_b2\n",
    "    # Remove sigmoid from origin GAN\n",
    "#     D_prob = tf.nn.sigmoid(D_logit)\n",
    "    return D_logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot(samples):\n",
    "    fig = plt.figure(figsize=(4,4))\n",
    "    gs = gridspec.GridSpec(4,4)\n",
    "    gs.update(wspace=0.05, hspace=0.05)\n",
    "    \n",
    "    for i, sample in enumerate(samples):\n",
    "        ax = plt.subplot(gs[i])\n",
    "        plt.axis('off')\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_aspect('equal')\n",
    "        plt.imshow(sample.reshape(28,28),cmap='Greys_r')\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G_sample = generator(Z)\n",
    "D_logit_real = discriminator(X)\n",
    "D_logit_fake = discriminator(G_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# D_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logit_real, labels=tf.ones_like(D_logit_real)))\n",
    "# D_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logit_fake, labels=tf.zeros_like(D_logit_fake)))\n",
    "# D_loss = D_loss_real + D_loss_fake\n",
    "\n",
    "# G_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logit_fake, labels=tf.ones_like(D_logit_fake)))\n",
    "\n",
    "# D_solver = tf.train.AdamOptimizer().minimize(D_loss, var_list=theta_D)\n",
    "# G_solver = tf.train.AdamOptimizer().minimize(G_loss, var_list=theta_G)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D_loss = tf.reduce_mean(D_logit_real) - tf.reduce_mean(D_logit_fake)\n",
    "G_loss = -tf.reduce_mean(D_logit_fake)\n",
    "\n",
    "# Here we need to add minus, because the update of w_d is w_d = w_d + lr * descent\n",
    "# However for tensorflow, its defulat operation should be w = w - lr * descent\n",
    "D_solver = tf.train.RMSPropOptimizer(learning_rate=1e-4).minimize(-D_loss, var_list=theta_D)\n",
    "G_solver = tf.train.RMSPropOptimizer(learning_rate=1e-4).minimize(G_loss, var_list=theta_G)\n",
    "\n",
    "# Only clip the w, no b\n",
    "clip_D = [p.assign(tf.clip_by_value(p,-0.01,0.01)) for p in theta_D[:2]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../../common_dataset/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ../../common_dataset/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ../../common_dataset/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../../common_dataset/MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('../../common_dataset/MNIST_data',one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('out/'):\n",
    "    os.makedirs('out/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# i=0\n",
    "# for it in range(10000):\n",
    "#     if it%1000 == 0:\n",
    "#         samples = sess.run(G_sample, feed_dict={Z:sample_Z(16,Z_dim)})\n",
    "        \n",
    "#         fig = plot(samples)\n",
    "#         plt.savefig('out/{}.png'.format(str(i).zfill(3)), bbox_inches='tight')\n",
    "#         i+=1\n",
    "#         plt.close(fig)\n",
    "    \n",
    "#     X_mb, _ = mnist.train.next_batch(mb_size)\n",
    "#     _, D_loss_curr = sess.run([D_solver, D_loss], feed_dict={X:X_mb, Z:sample_Z(mb_size,Z_dim)})\n",
    "#     _, G_loss_curr = sess.run([G_solver, G_loss], feed_dict={Z:sample_Z(mb_size, Z_dim)})\n",
    "#     if it % 1000 == 0:\n",
    "#         print('Iter:{}'.format(it))\n",
    "#         print('D_loss:{:.4}'.format(D_loss_curr))\n",
    "#         print('G_loss:{:.4}'.format(G_loss_curr))\n",
    "#         print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:0; D_loss: -0.00185; G_loss: -0.004683\n",
      "Iter:100; D_loss: 1.864; G_loss: 1.482\n",
      "Iter:200; D_loss: 1.837; G_loss: 1.317\n",
      "Iter:300; D_loss: 1.551; G_loss: 1.047\n",
      "Iter:400; D_loss: 1.31; G_loss: 0.8539\n",
      "Iter:500; D_loss: 1.023; G_loss: 0.7486\n",
      "Iter:600; D_loss: 0.7314; G_loss: 0.6002\n",
      "Iter:700; D_loss: 0.4776; G_loss: 0.4923\n",
      "Iter:800; D_loss: 0.3171; G_loss: 0.1116\n",
      "Iter:900; D_loss: 0.1153; G_loss: -0.105\n",
      "Iter:1000; D_loss: 0.06079; G_loss: -0.2318\n",
      "Iter:1100; D_loss: 0.06331; G_loss: -0.1703\n",
      "Iter:1200; D_loss: 0.02523; G_loss: -0.1925\n",
      "Iter:1300; D_loss: 0.01195; G_loss: -0.3216\n",
      "Iter:1400; D_loss: 0.01575; G_loss: -0.2808\n",
      "Iter:1500; D_loss: 0.003801; G_loss: -0.2417\n",
      "Iter:1600; D_loss: 0.009472; G_loss: -0.2177\n",
      "Iter:1700; D_loss: 0.007447; G_loss: -0.2341\n",
      "Iter:1800; D_loss: 0.006432; G_loss: -0.2945\n",
      "Iter:1900; D_loss: 0.01477; G_loss: -0.3487\n",
      "Iter:2000; D_loss: 0.01318; G_loss: -0.3736\n",
      "Iter:2100; D_loss: 0.01352; G_loss: -0.1205\n",
      "Iter:2200; D_loss: 0.003655; G_loss: -0.2891\n",
      "Iter:2300; D_loss: -0.001754; G_loss: -0.256\n",
      "Iter:2400; D_loss: 0.001155; G_loss: -0.09398\n",
      "Iter:2500; D_loss: 0.007112; G_loss: -0.2065\n",
      "Iter:2600; D_loss: 0.0001029; G_loss: -0.08361\n",
      "Iter:2700; D_loss: 0.00315; G_loss: -0.02448\n",
      "Iter:2800; D_loss: 0.01145; G_loss: -0.1208\n",
      "Iter:2900; D_loss: 0.003536; G_loss: -0.07963\n",
      "Iter:3000; D_loss: -0.003679; G_loss: -0.02831\n",
      "Iter:3100; D_loss: 0.003578; G_loss: -0.02264\n",
      "Iter:3200; D_loss: 0.005952; G_loss: 0.09978\n",
      "Iter:3300; D_loss: 0.006107; G_loss: -0.06697\n",
      "Iter:3400; D_loss: 0.004062; G_loss: 0.03995\n",
      "Iter:3500; D_loss: 0.04422; G_loss: -0.04806\n",
      "Iter:3600; D_loss: 0.06059; G_loss: 0.1024\n",
      "Iter:3700; D_loss: 0.0452; G_loss: 0.1012\n",
      "Iter:3800; D_loss: 0.04689; G_loss: 0.04876\n",
      "Iter:3900; D_loss: 0.01375; G_loss: -0.002666\n",
      "Iter:4000; D_loss: 0.04869; G_loss: 0.0228\n",
      "Iter:4100; D_loss: 0.04623; G_loss: 0.0177\n",
      "Iter:4200; D_loss: 0.04514; G_loss: 0.07302\n",
      "Iter:4300; D_loss: 0.04576; G_loss: -0.02136\n",
      "Iter:4400; D_loss: 0.04067; G_loss: -0.0104\n",
      "Iter:4500; D_loss: 0.05257; G_loss: -0.06263\n",
      "Iter:4600; D_loss: 0.03552; G_loss: 0.01091\n",
      "Iter:4700; D_loss: 0.04204; G_loss: 0.002826\n",
      "Iter:4800; D_loss: 0.03067; G_loss: 0.00213\n",
      "Iter:4900; D_loss: 0.03352; G_loss: -0.003582\n",
      "Iter:5000; D_loss: 0.03736; G_loss: 0.03666\n",
      "Iter:5100; D_loss: 0.03712; G_loss: 0.01229\n",
      "Iter:5200; D_loss: 0.03736; G_loss: 0.002056\n",
      "Iter:5300; D_loss: 0.03845; G_loss: 0.02197\n",
      "Iter:5400; D_loss: 0.03728; G_loss: 0.02603\n",
      "Iter:5500; D_loss: 0.03095; G_loss: -0.009648\n",
      "Iter:5600; D_loss: 0.03279; G_loss: -0.003286\n",
      "Iter:5700; D_loss: 0.02995; G_loss: 0.01106\n",
      "Iter:5800; D_loss: 0.03709; G_loss: 0.004747\n",
      "Iter:5900; D_loss: 0.0337; G_loss: -0.01503\n",
      "Iter:6000; D_loss: 0.03453; G_loss: 0.01652\n",
      "Iter:6100; D_loss: 0.03354; G_loss: -0.008259\n",
      "Iter:6200; D_loss: 0.02746; G_loss: -0.01348\n",
      "Iter:6300; D_loss: 0.03786; G_loss: -0.03244\n",
      "Iter:6400; D_loss: 0.03231; G_loss: 0.007609\n",
      "Iter:6500; D_loss: 0.03191; G_loss: 0.03664\n",
      "Iter:6600; D_loss: 0.03134; G_loss: 0.04186\n",
      "Iter:6700; D_loss: 0.0317; G_loss: -0.01114\n",
      "Iter:6800; D_loss: 0.03347; G_loss: 0.009696\n",
      "Iter:6900; D_loss: 0.03704; G_loss: 0.03242\n",
      "Iter:7000; D_loss: 0.03385; G_loss: -0.01668\n",
      "Iter:7100; D_loss: 0.03318; G_loss: 0.0006546\n",
      "Iter:7200; D_loss: 0.03544; G_loss: -0.01307\n",
      "Iter:7300; D_loss: 0.03216; G_loss: 0.004042\n",
      "Iter:7400; D_loss: 0.03375; G_loss: -0.05184\n",
      "Iter:7500; D_loss: 0.04217; G_loss: -0.03347\n",
      "Iter:7600; D_loss: 0.03641; G_loss: -0.02766\n",
      "Iter:7700; D_loss: 0.02742; G_loss: -0.01513\n",
      "Iter:7800; D_loss: 0.0418; G_loss: -0.03388\n",
      "Iter:7900; D_loss: 0.03585; G_loss: -0.01904\n",
      "Iter:8000; D_loss: 0.03491; G_loss: -0.06184\n",
      "Iter:8100; D_loss: 0.03797; G_loss: -0.03758\n",
      "Iter:8200; D_loss: 0.03641; G_loss: -0.07599\n",
      "Iter:8300; D_loss: 0.03888; G_loss: -0.05405\n",
      "Iter:8400; D_loss: 0.03162; G_loss: -0.05941\n",
      "Iter:8500; D_loss: 0.03878; G_loss: -0.06423\n",
      "Iter:8600; D_loss: 0.02916; G_loss: -0.03757\n",
      "Iter:8700; D_loss: 0.03612; G_loss: -0.07158\n",
      "Iter:8800; D_loss: 0.03963; G_loss: -0.03667\n",
      "Iter:8900; D_loss: 0.0369; G_loss: -0.06819\n",
      "Iter:9000; D_loss: 0.03592; G_loss: -0.02844\n",
      "Iter:9100; D_loss: 0.03107; G_loss: -0.04355\n",
      "Iter:9200; D_loss: 0.03508; G_loss: -0.05268\n",
      "Iter:9300; D_loss: 0.03451; G_loss: -0.04386\n",
      "Iter:9400; D_loss: 0.02917; G_loss: -0.01981\n",
      "Iter:9500; D_loss: 0.03769; G_loss: -0.03061\n",
      "Iter:9600; D_loss: 0.03056; G_loss: -0.06473\n",
      "Iter:9700; D_loss: 0.03495; G_loss: -0.0062\n",
      "Iter:9800; D_loss: 0.03557; G_loss: -0.007318\n",
      "Iter:9900; D_loss: 0.0324; G_loss: -0.1015\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for it in range(10000):\n",
    "    for _ in range(5):\n",
    "        X_mb, _ = mnist.train.next_batch(mb_size)\n",
    "        \n",
    "        _, D_loss_curr, _ = sess.run([D_solver, D_loss, clip_D],\n",
    "                                    feed_dict={X:X_mb, Z:sample_Z(mb_size, Z_dim)})\n",
    "    \n",
    "    _, G_loss_curr = sess.run([G_solver, G_loss],\n",
    "                             feed_dict={Z:sample_Z(mb_size, Z_dim)})\n",
    "    \n",
    "    if it % 100 == 0:\n",
    "        print('Iter:{}; D_loss: {:.4}; G_loss: {:.4}'.format(it, D_loss_curr, G_loss_curr))\n",
    "        \n",
    "        if it % 1000 == 0:\n",
    "            samples = sess.run(G_sample, feed_dict={Z:sample_Z(16,Z_dim)})\n",
    "            fig = plot(samples)\n",
    "            plt.savefig('out/{}.png'.format(str(i).zfill(3)), bbox_inches='tight')\n",
    "            i += 1\n",
    "            plt.close(fig)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

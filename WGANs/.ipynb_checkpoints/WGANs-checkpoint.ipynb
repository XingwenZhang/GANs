{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def variable_init(size):\n",
    "    in_dim = size[0]\n",
    "#     variable_stddev = 1./tf.sqrt(in_dim/2.)\n",
    "    variable_stddev = tf.sqrt(2./in_dim)\n",
    "    return tf.random_normal(shape=size,stddev=variable_stddev)\n",
    "#     return tf.random_normal(shape=size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None,784])\n",
    "\n",
    "D_W1 = tf.Variable(variable_init([784,128]))\n",
    "D_b1 = tf.Variable(tf.zeros(shape=[128]))\n",
    "\n",
    "D_W2 = tf.Variable(variable_init([128, 1]))\n",
    "D_b2 = tf.Variable(tf.zeros(shape=[1]))\n",
    "\n",
    "theta_D = [D_W1, D_W2, D_b1, D_b2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Z = tf.placeholder(tf.float32, shape=[None, 100])\n",
    "\n",
    "G_W1 = tf.Variable(variable_init([100,128]))\n",
    "G_b1 = tf.Variable(tf.zeros(shape=[128]))\n",
    "\n",
    "G_W2 = tf.Variable(variable_init([128,784]))\n",
    "G_b2 = tf.Variable(tf.zeros(shape=[784]))\n",
    "\n",
    "theta_G = [G_W1, G_W2, G_b1, G_b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_Z(m,n):\n",
    "    return np.random.uniform(-1., 1., size=[m,n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator(z):\n",
    "    G_h1 = tf.nn.relu(tf.matmul(z, G_W1) + G_b1)\n",
    "    G_prob = tf.nn.sigmoid(tf.matmul(G_h1, G_W2) + G_b2)\n",
    "    return G_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discriminator(x):\n",
    "    D_h1 = tf.nn.relu(tf.matmul(x, D_W1) + D_b1)\n",
    "    D_logit = tf.matmul(D_h1, D_W2) + D_b2\n",
    "    # Remove sigmoid from origin GAN\n",
    "#     D_prob = tf.nn.sigmoid(D_logit)\n",
    "    return D_logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot(samples):\n",
    "    fig = plt.figure(figsize=(4,4))\n",
    "    gs = gridspec.GridSpec(4,4)\n",
    "    gs.update(wspace=0.05, hspace=0.05)\n",
    "    \n",
    "    for i, sample in enumerate(samples):\n",
    "        ax = plt.subplot(gs[i])\n",
    "        plt.axis('off')\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_aspect('equal')\n",
    "        plt.imshow(sample.reshape(28,28),cmap='Greys_r')\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G_sample = generator(Z)\n",
    "D_logit_real = discriminator(X)\n",
    "D_logit_fake = discriminator(G_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# D_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logit_real, labels=tf.ones_like(D_logit_real)))\n",
    "# D_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logit_fake, labels=tf.zeros_like(D_logit_fake)))\n",
    "# D_loss = D_loss_real + D_loss_fake\n",
    "\n",
    "# G_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logit_fake, labels=tf.ones_like(D_logit_fake)))\n",
    "\n",
    "# D_solver = tf.train.AdamOptimizer().minimize(D_loss, var_list=theta_D)\n",
    "# G_solver = tf.train.AdamOptimizer().minimize(G_loss, var_list=theta_G)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D_loss = tf.reduce_mean(D_logit_real) - tf.reduce_mean(D_logit_fake)\n",
    "G_loss = -tf.reduce_mean(D_logit_fake)\n",
    "\n",
    "# Here we need to add minus, because the update of w_d is w_d = w_d + lr * descent\n",
    "# However for tensorflow, its defulat operation should be w = w - lr * descent\n",
    "D_solver = tf.train.RMSPropOptimizer(learning_rate=5e-5).minimize(-D_loss, var_list=theta_D)\n",
    "G_solver = tf.train.RMSPropOptimizer(learning_rate=5e-5).minimize(G_loss, var_list=theta_G)\n",
    "\n",
    "# Only clip the w, no b\n",
    "clip_D = [p.assign(tf.clip_by_value(p,-0.01,0.01)) for p in theta_D[:2]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mb_size = 64\n",
    "Z_dim = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../../common_dataset/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ../../common_dataset/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ../../common_dataset/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../../common_dataset/MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('../../common_dataset/MNIST_data',one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('out/'):\n",
    "    os.makedirs('out/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i=0\n",
    "# for it in range(10000):\n",
    "#     if it%1000 == 0:\n",
    "#         samples = sess.run(G_sample, feed_dict={Z:sample_Z(16,Z_dim)})\n",
    "        \n",
    "#         fig = plot(samples)\n",
    "#         plt.savefig('out/{}.png'.format(str(i).zfill(3)), bbox_inches='tight')\n",
    "#         i+=1\n",
    "#         plt.close(fig)\n",
    "    \n",
    "#     X_mb, _ = mnist.train.next_batch(mb_size)\n",
    "#     _, D_loss_curr = sess.run([D_solver, D_loss], feed_dict={X:X_mb, Z:sample_Z(mb_size,Z_dim)})\n",
    "#     _, G_loss_curr = sess.run([G_solver, G_loss], feed_dict={Z:sample_Z(mb_size, Z_dim)})\n",
    "#     if it % 1000 == 0:\n",
    "#         print('Iter:{}'.format(it))\n",
    "#         print('D_loss:{:.4}'.format(D_loss_curr))\n",
    "#         print('G_loss:{:.4}'.format(G_loss_curr))\n",
    "#         print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:0; D_loss: 0.003932; G_loss: 0.004381\n",
      "Iter:100; D_loss: 2.023; G_loss: 1.672\n",
      "Iter:200; D_loss: 1.961; G_loss: 1.592\n",
      "Iter:300; D_loss: 1.829; G_loss: 1.405\n",
      "Iter:400; D_loss: 1.672; G_loss: 1.238\n",
      "Iter:500; D_loss: 1.559; G_loss: 1.119\n",
      "Iter:600; D_loss: 1.405; G_loss: 0.9803\n",
      "Iter:700; D_loss: 1.285; G_loss: 0.9692\n",
      "Iter:800; D_loss: 1.109; G_loss: 0.9113\n",
      "Iter:900; D_loss: 0.8616; G_loss: 0.841\n",
      "Iter:1000; D_loss: 0.7304; G_loss: 0.7472\n",
      "Iter:1100; D_loss: 0.5839; G_loss: 0.6179\n",
      "Iter:1200; D_loss: 0.44; G_loss: 0.3934\n",
      "Iter:1300; D_loss: 0.3261; G_loss: 0.1604\n",
      "Iter:1400; D_loss: 0.2488; G_loss: 0.06658\n",
      "Iter:1500; D_loss: 0.1892; G_loss: -0.003064\n",
      "Iter:1600; D_loss: 0.1276; G_loss: -0.04707\n",
      "Iter:1700; D_loss: 0.09586; G_loss: -0.09202\n",
      "Iter:1800; D_loss: 0.07045; G_loss: -0.1346\n",
      "Iter:1900; D_loss: 0.04566; G_loss: -0.1704\n",
      "Iter:2000; D_loss: 0.03082; G_loss: -0.1494\n",
      "Iter:2100; D_loss: 0.02671; G_loss: -0.186\n",
      "Iter:2200; D_loss: 0.01864; G_loss: -0.2142\n",
      "Iter:2300; D_loss: 0.01226; G_loss: -0.1838\n",
      "Iter:2400; D_loss: 0.009572; G_loss: -0.2166\n",
      "Iter:2500; D_loss: 0.005587; G_loss: -0.2051\n",
      "Iter:2600; D_loss: 0.005708; G_loss: -0.2229\n",
      "Iter:2700; D_loss: 0.004492; G_loss: -0.2029\n",
      "Iter:2800; D_loss: 0.004775; G_loss: -0.2011\n",
      "Iter:2900; D_loss: 0.004773; G_loss: -0.1734\n",
      "Iter:3000; D_loss: 0.001929; G_loss: -0.2107\n",
      "Iter:3100; D_loss: 0.004839; G_loss: -0.1586\n",
      "Iter:3200; D_loss: 0.001992; G_loss: -0.2114\n",
      "Iter:3300; D_loss: 0.004395; G_loss: -0.226\n",
      "Iter:3400; D_loss: 0.002954; G_loss: -0.1616\n",
      "Iter:3500; D_loss: 0.004194; G_loss: -0.1901\n",
      "Iter:3600; D_loss: 0.002854; G_loss: -0.1719\n",
      "Iter:3700; D_loss: 0.004745; G_loss: -0.2021\n",
      "Iter:3800; D_loss: 0.003088; G_loss: -0.124\n",
      "Iter:3900; D_loss: 0.002881; G_loss: -0.1624\n",
      "Iter:4000; D_loss: 0.002029; G_loss: -0.1653\n",
      "Iter:4100; D_loss: 0.004147; G_loss: -0.2154\n",
      "Iter:4200; D_loss: 0.004438; G_loss: -0.2206\n",
      "Iter:4300; D_loss: 0.00225; G_loss: -0.1657\n",
      "Iter:4400; D_loss: 0.003613; G_loss: -0.1515\n",
      "Iter:4500; D_loss: 0.003985; G_loss: -0.2092\n",
      "Iter:4600; D_loss: 0.003989; G_loss: -0.1481\n",
      "Iter:4700; D_loss: -0.0008951; G_loss: -0.2205\n",
      "Iter:4800; D_loss: 0.002894; G_loss: -0.2371\n",
      "Iter:4900; D_loss: 0.004876; G_loss: -0.2681\n",
      "Iter:5000; D_loss: 0.00296; G_loss: -0.1475\n",
      "Iter:5100; D_loss: 0.003532; G_loss: -0.1536\n",
      "Iter:5200; D_loss: 0.004021; G_loss: -0.1648\n",
      "Iter:5300; D_loss: 0.005613; G_loss: -0.1922\n",
      "Iter:5400; D_loss: 0.002841; G_loss: -0.1809\n",
      "Iter:5500; D_loss: 0.00561; G_loss: -0.0777\n",
      "Iter:5600; D_loss: 0.001246; G_loss: -0.1801\n",
      "Iter:5700; D_loss: 0.0008312; G_loss: -0.186\n",
      "Iter:5800; D_loss: 0.003028; G_loss: -0.1595\n",
      "Iter:5900; D_loss: 0.00348; G_loss: -0.1139\n",
      "Iter:6000; D_loss: 0.002242; G_loss: -0.1739\n",
      "Iter:6100; D_loss: 0.001815; G_loss: -0.144\n",
      "Iter:6200; D_loss: 0.001312; G_loss: -0.1145\n",
      "Iter:6300; D_loss: 0.000536; G_loss: -0.177\n",
      "Iter:6400; D_loss: 0.001556; G_loss: -0.08739\n",
      "Iter:6500; D_loss: 0.001656; G_loss: -0.1369\n",
      "Iter:6600; D_loss: 0.003165; G_loss: -0.08238\n",
      "Iter:6700; D_loss: 0.002891; G_loss: -0.1566\n",
      "Iter:6800; D_loss: 0.002859; G_loss: -0.145\n",
      "Iter:6900; D_loss: 0.003232; G_loss: -0.1475\n",
      "Iter:7000; D_loss: 0.000845; G_loss: -0.09664\n",
      "Iter:7100; D_loss: 0.001651; G_loss: -0.09532\n",
      "Iter:7200; D_loss: 0.005569; G_loss: -0.1297\n",
      "Iter:7300; D_loss: 0.002889; G_loss: -0.07644\n",
      "Iter:7400; D_loss: -0.0006245; G_loss: -0.06632\n",
      "Iter:7500; D_loss: 0.001185; G_loss: -0.1304\n",
      "Iter:7600; D_loss: 0.001313; G_loss: -0.1046\n",
      "Iter:7700; D_loss: 0.002672; G_loss: -0.0698\n",
      "Iter:7800; D_loss: 0.003082; G_loss: -0.06257\n",
      "Iter:7900; D_loss: 0.003149; G_loss: -0.07673\n",
      "Iter:8000; D_loss: 0.001575; G_loss: -0.0744\n",
      "Iter:8100; D_loss: 0.002157; G_loss: -0.1149\n",
      "Iter:8200; D_loss: 0.002352; G_loss: -0.051\n",
      "Iter:8300; D_loss: 0.002145; G_loss: -0.05577\n",
      "Iter:8400; D_loss: 0.003028; G_loss: -0.03042\n",
      "Iter:8500; D_loss: 0.0006153; G_loss: -0.02186\n",
      "Iter:8600; D_loss: 0.002481; G_loss: -0.03379\n",
      "Iter:8700; D_loss: 0.00242; G_loss: -0.0525\n",
      "Iter:8800; D_loss: 0.002626; G_loss: -0.04274\n",
      "Iter:8900; D_loss: 0.002453; G_loss: -0.03314\n",
      "Iter:9000; D_loss: 0.003566; G_loss: -0.07924\n",
      "Iter:9100; D_loss: 0.002587; G_loss: 0.000711\n",
      "Iter:9200; D_loss: 0.0007951; G_loss: -0.09618\n",
      "Iter:9300; D_loss: 0.002002; G_loss: -0.001256\n",
      "Iter:9400; D_loss: 0.002804; G_loss: 0.01216\n",
      "Iter:9500; D_loss: 0.004395; G_loss: 0.02296\n",
      "Iter:9600; D_loss: 0.001832; G_loss: -0.07584\n",
      "Iter:9700; D_loss: 0.002631; G_loss: -0.08578\n",
      "Iter:9800; D_loss: -0.0005639; G_loss: 0.0167\n",
      "Iter:9900; D_loss: 0.003295; G_loss: -0.08057\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for it in range(10000):\n",
    "    for _ in range(5):\n",
    "        X_mb, _ = mnist.train.next_batch(mb_size)\n",
    "        \n",
    "        _, D_loss_curr, _ = sess.run([D_solver, D_loss, clip_D],\n",
    "                                    feed_dict={X:X_mb, Z:sample_Z(mb_size, Z_dim)})\n",
    "    \n",
    "    _, G_loss_curr = sess.run([G_solver, G_loss],\n",
    "                             feed_dict={Z:sample_Z(mb_size, Z_dim)})\n",
    "    \n",
    "    if it % 100 == 0:\n",
    "        print('Iter:{}; D_loss: {:.4}; G_loss: {:.4}'.format(it, D_loss_curr, G_loss_curr))\n",
    "        \n",
    "        if it % 1000 == 0:\n",
    "            samples = sess.run(G_sample, feed_dict={Z:sample_Z(16,Z_dim)})\n",
    "            fig = plot(samples)\n",
    "            plt.savefig('out/{}.png'.format(str(i).zfill(3)), bbox_inches='tight')\n",
    "            i += 1\n",
    "            plt.close(fig)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
